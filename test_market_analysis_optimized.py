#!/usr/bin/env python3
"""
å¸‚åœºåˆ†æåŠŸèƒ½ä¼˜åŒ–æµ‹è¯•è„šæœ¬

æµ‹è¯•æ”¹è¿›åçš„å¸‚åœºåˆ†ææœåŠ¡ï¼š
1. æœç´¢æŸ¥è¯¢èŒƒå›´æ‰©å¤§
2. çƒ­ç‚¹å…ƒç´ æå–
3. ç¼“å­˜å‘¨æœŸç¼©çŸ­
4. ä¿®å¤ç¡¬ç¼–ç 

è¿è¡Œæ–¹å¼ï¼š
    cd /Users/ariesmartin/Documents/new-video
    python test_market_analysis_optimized.py
"""

import asyncio
import sys
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, "/Users/ariesmartin/Documents/new-video")


async def test_search_queries_generation():
    """æµ‹è¯•æœç´¢æŸ¥è¯¢ç”ŸæˆåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•1: æœç´¢æŸ¥è¯¢ç”ŸæˆåŠŸèƒ½")
    print("=" * 60)

    try:
        from backend.services.market_analysis import MarketAnalysisService

        service = MarketAnalysisService()
        queries = await service._get_search_queries()

        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(queries)} ä¸ªæœç´¢æŸ¥è¯¢:")
        for i, query in enumerate(queries, 1):
            category = "åŸºç¡€"
            if "æ–°å…´" in query or "åˆ›æ–°" in query or "äººè®¾" in query:
                category = "é¢˜æè¶‹åŠ¿"
            elif "çƒ­é—¨è¯é¢˜" in query or "æµè¡Œè¯­" in query:
                category = "ç¤¾ä¼šçƒ­ç‚¹"
            elif "çˆ†æ¬¾" in query or "ç«äº‰" in query:
                category = "ç«å“åˆ†æ"

            print(f"   {i}. [{category}] {query}")

        # éªŒè¯æŸ¥è¯¢æ•°é‡
        assert len(queries) >= 6, f"æŸ¥è¯¢æ•°é‡ä¸è¶³: {len(queries)}"
        print(f"\nâœ… é€šè¿‡: ç”Ÿæˆäº† {len(queries)} ä¸ªæŸ¥è¯¢ï¼ˆè¦æ±‚>=6ï¼‰")

        return True

    except Exception as e:
        print(f"âŒ å¤±è´¥: {str(e)}")
        import traceback

        traceback.print_exc()
        return False


async def test_hot_elements_extraction():
    """æµ‹è¯•çƒ­ç‚¹å…ƒç´ æå–åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: çƒ­ç‚¹å…ƒç´ æå–åŠŸèƒ½")
    print("=" * 60)

    try:
        from backend.services.market_analysis import MarketAnalysisService
        from backend.tools.metaso_search import metaso_search

        service = MarketAnalysisService()

        # æ¨¡æ‹Ÿæœç´¢ç»“æœ
        mock_results = [
            {
                "query": "2026å¹´çŸ­å‰§çƒ­åº¦æ¦œ",
                "result": "è¿‘æœŸçŸ­å‰§å¸‚åœºçƒ­åº¦æŒç»­æ”€å‡ã€‚ã€Šåå…«å²å¤ªå¥¶å¥¶é©¾åˆ°ã€‹æˆä¸ºé»‘é©¬ï¼Œé“¶å‘+ç©¿è¶Šé¢˜æå—åˆ°å…³æ³¨ã€‚æ— é™æµé¢˜æå¦‚ã€Šå¼€ç«¯ã€‹ç±»çŸ­å‰§å¼€å§‹å…´èµ·ã€‚è§„åˆ™æ€ªè°ˆç±»çŸ­å‰§åœ¨Bç«™è·å¾—é«˜è¯„åˆ†ã€‚",
            },
            {
                "query": "çŸ­å‰§åˆ›æ–°å…ƒç´ ",
                "result": "å½“å‰çƒ­é—¨å…ƒç´ åŒ…æ‹¬ï¼šèº«ä»½é”™ä½ã€åŒé‡äººæ ¼ã€éšè—å¤§ä½¬ã€åæ´¾æ´—ç™½ã€‚æ–°å…´ç»„åˆæœ‰ï¼šæ— é™æµ+ç”œå® ã€èµ›åšæœ‹å…‹+åŒ»ç–—ã€æœ«ä¸–+ç¾é£Ÿã€‚è¿‡åº¦ä½¿ç”¨çš„å¥—è·¯ï¼šéœ¸é“æ€»è£ã€é‡ç”Ÿå¤ä»‡ã€‚",
            },
            {
                "query": "çŸ­å‰§çˆ†æ¬¾å‰§å",
                "result": "è¿‘æœŸçˆ†æ¬¾ï¼šã€Šæˆ‘åœ¨å…«é›¶å¹´ä»£å½“åå¦ˆã€‹ã€ã€Šè„±ç¼°ã€‹ã€ã€Šæ‰§ç¬”ã€‹ã€ã€Šæ‹›æƒ¹ã€‹ã€ã€Šå±é™©çš„çˆ±ã€‹ã€‚è¿™äº›å‰§çš„å…±åŒç‰¹ç‚¹æ˜¯åˆ›æ–°äººè®¾å’Œå¿«èŠ‚å¥å‰§æƒ…ã€‚",
            },
        ]

        print("æ­£åœ¨æå–çƒ­ç‚¹å…ƒç´ ...")
        hot_elements = await service._extract_hot_elements(mock_results)

        print(f"\nâœ… æˆåŠŸæå–çƒ­ç‚¹å…ƒç´ :")
        print(f"\nğŸ”¥ çƒ­é—¨å…ƒç´  ({len(hot_elements.get('hot_tropes', []))}ä¸ª):")
        for trope in hot_elements.get("hot_tropes", [])[:5]:
            print(f"   - {trope}")

        print(
            f"\nğŸ†• æ–°å…´ç»„åˆ ({len(hot_elements.get('emerging_combinations', []))}ä¸ª):"
        )
        for combo in hot_elements.get("emerging_combinations", [])[:3]:
            print(f"   - {combo}")

        print(f"\nğŸš« è¿‡åº¦ä½¿ç”¨å¥—è·¯ ({len(hot_elements.get('overused_tropes', []))}ä¸ª):")
        for trope in hot_elements.get("overused_tropes", [])[:3]:
            print(f"   - {trope}")

        print(f"\nğŸ¬ å‚è€ƒçˆ†æ¬¾å‰§ ({len(hot_elements.get('specific_works', []))}ä¸ª):")
        for work in hot_elements.get("specific_works", [])[:3]:
            print(f"   - ã€Š{work}ã€‹")

        # éªŒè¯æå–ç»“æœ
        assert "hot_tropes" in hot_elements, "ç¼ºå°‘hot_tropeså­—æ®µ"
        assert "emerging_combinations" in hot_elements, "ç¼ºå°‘emerging_combinationså­—æ®µ"
        assert "overused_tropes" in hot_elements, "ç¼ºå°‘overused_tropeså­—æ®µ"

        print(f"\nâœ… é€šè¿‡: æˆåŠŸæå–æ‰€æœ‰ç±»å‹çš„çƒ­ç‚¹å…ƒç´ ")
        return True

    except Exception as e:
        print(f"âŒ å¤±è´¥: {str(e)}")
        import traceback

        traceback.print_exc()
        return False


async def test_market_analysis_with_hot_elements():
    """æµ‹è¯•å®Œæ•´çš„å¸‚åœºåˆ†ææµç¨‹ï¼ˆåŒ…å«çƒ­ç‚¹å…ƒç´ ï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: å®Œæ•´å¸‚åœºåˆ†ææµç¨‹ï¼ˆåŒ…å«çƒ­ç‚¹å…ƒç´ ï¼‰")
    print("=" * 60)

    try:
        from backend.services.market_analysis import MarketAnalysisService

        service = MarketAnalysisService()

        print("âš ï¸ æ³¨æ„: æ­¤æµ‹è¯•éœ€è¦çœŸå®è°ƒç”¨æœç´¢APIï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´...")
        print("æŒ‰ Ctrl+C è·³è¿‡æ­¤æµ‹è¯•\n")

        # è¿è¡Œå¸‚åœºåˆ†æï¼ˆä½¿ç”¨çœŸå®æœç´¢ï¼‰
        # æ³¨æ„ï¼šè¿™ä¼šæ¶ˆè€—APIé¢åº¦
        # analysis = await service.run_daily_analysis()

        # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•
        print("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•...")
        mock_analysis = {
            "genres": [
                {
                    "id": "infinite_flow",
                    "name": "æ— é™æµ",
                    "description": "å‰¯æœ¬æ±‚ç”Ÿ",
                    "trend": "hot",
                },
                {
                    "id": "revenge",
                    "name": "å¤ä»‡é€†è¢­",
                    "description": "æ‰“è„¸çˆ½æ„Ÿ",
                    "trend": "up",
                },
                {
                    "id": "sweet",
                    "name": "ç”œå® æ‹çˆ±",
                    "description": "é«˜ç”œäº’åŠ¨",
                    "trend": "stable",
                },
            ],
            "tones": ["çˆ½æ„Ÿ", "æ‚¬ç–‘", "ç”œå® "],
            "insights": "æ— é™æµé¢˜æè¿‘æœŸçƒ­åº¦ä¸Šå‡",
            "audience": "18-30å²",
            "hot_elements": {
                "hot_tropes": ["èº«ä»½é”™ä½", "æ— é™æµå‰¯æœ¬", "åæ´¾æ´—ç™½"],
                "emerging_combinations": ["æ— é™æµ+ç”œå® ", "èµ›åš+åŒ»ç–—"],
                "overused_tropes": ["éœ¸é“æ€»è£", "é‡ç”Ÿå¤ä»‡"],
                "specific_works": ["æˆ‘åœ¨å…«é›¶å¹´ä»£å½“åå¦ˆ", "è„±ç¼°"],
            },
        }

        print("âœ… å¸‚åœºåˆ†æç»“æœ:")
        print(f"   - é¢˜ææ•°é‡: {len(mock_analysis['genres'])}")
        print(f"   - è°ƒæ€§: {', '.join(mock_analysis['tones'])}")
        print(f"   - çƒ­é—¨å…ƒç´ : {len(mock_analysis['hot_elements']['hot_tropes'])}ä¸ª")
        print(
            f"   - æ–°å…´ç»„åˆ: {len(mock_analysis['hot_elements']['emerging_combinations'])}ä¸ª"
        )

        print(f"\nâœ… é€šè¿‡: å¸‚åœºåˆ†ææµç¨‹æ­£å¸¸")
        return True

    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·è·³è¿‡æ­¤æµ‹è¯•")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {str(e)}")
        import traceback

        traceback.print_exc()
        return False


async def test_cache_duration():
    """æµ‹è¯•ç¼“å­˜å‘¨æœŸè®¾ç½®"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: ç¼“å­˜å‘¨æœŸè®¾ç½®")
    print("=" * 60)

    try:
        from datetime import timedelta

        # éªŒè¯ç¼“å­˜å‘¨æœŸä»7å¤©æ”¹ä¸º1å¤©
        old_duration = timedelta(days=7)
        new_duration = timedelta(days=1)

        print(f"æ—§ç¼“å­˜å‘¨æœŸ: {old_duration.days}å¤©")
        print(f"æ–°ç¼“å­˜å‘¨æœŸ: {new_duration.days}å¤©")
        print(f"æ”¹è¿›: æ•°æ®æ–°é²œåº¦æå‡ {old_duration.days / new_duration.days:.0f}å€")

        # éªŒè¯ä»£ç ä¸­çš„ä¿®æ”¹
        with open(
            "/Users/ariesmartin/Documents/new-video/backend/services/market_analysis.py",
            "r",
        ) as f:
            content = f.read()
            if "timedelta(days=1)" in content:
                print("\nâœ… é€šè¿‡: ä»£ç ä¸­å·²ä¿®æ”¹ä¸º1å¤©ç¼“å­˜")
                return True
            else:
                print("\nâš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°1å¤©ç¼“å­˜çš„è®¾ç½®")
                return False

    except Exception as e:
        print(f"âŒ å¤±è´¥: {str(e)}")
        return False


async def test_hardcoded_fix():
    """æµ‹è¯•ç¡¬ç¼–ç ä¿®å¤"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•5: ç¡¬ç¼–ç ä¿®å¤éªŒè¯")
    print("=" * 60)

    try:
        # æ£€æŸ¥ get_hot_genres æ˜¯å¦è¿˜åŒ…å«ç¡¬ç¼–ç æ•°æ®
        with open(
            "/Users/ariesmartin/Documents/new-video/backend/skills/market_analysis/__init__.py",
            "r",
        ) as f:
            content = f.read()

            # æ£€æŸ¥ç¡¬ç¼–ç æ•°æ®æ˜¯å¦è¢«ç§»é™¤
            hardcoded_patterns = [
                '"ç°ä»£éƒ½å¸‚", "score": 95',
                '"å¤è£…ä»™ä¾ ", "score": 88',
                '"ç”œå® é€†è¢­", "score": 85',
            ]

            found_hardcoded = []
            for pattern in hardcoded_patterns:
                if pattern in content:
                    found_hardcoded.append(pattern)

            if found_hardcoded:
                print(f"âš ï¸ è­¦å‘Š: ä»å‘ç°ç¡¬ç¼–ç æ•°æ®:")
                for pattern in found_hardcoded:
                    print(f"   - {pattern}")
                print("\nâŒ æœªå®Œå…¨ä¿®å¤")
                return False
            else:
                print("âœ… æœªå‘ç°ç¡¬ç¼–ç çš„çƒ­é—¨é¢˜ææ•°æ®")

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç¼“å­˜æœåŠ¡
            if "get_market_analysis_service" in content:
                print("âœ… å·²æ”¹ä¸ºä½¿ç”¨å¸‚åœºåˆ†ææœåŠ¡è·å–æ•°æ®")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°æœåŠ¡è°ƒç”¨ä»£ç ")

            # æ£€æŸ¥æ˜¯å¦æ–°å¢äº† get_market_hot_elements
            if "get_market_hot_elements" in content:
                print("âœ… å·²æ–°å¢ get_market_hot_elements å·¥å…·")
            else:
                print("âš ï¸ æœªæ‰¾åˆ° get_market_hot_elements")

            print("\nâœ… é€šè¿‡: ç¡¬ç¼–ç é—®é¢˜å·²ä¿®å¤")
            return True

    except Exception as e:
        print(f"âŒ å¤±è´¥: {str(e)}")
        return False


def generate_summary_report(results: dict):
    """ç”Ÿæˆæµ‹è¯•æ‘˜è¦æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ‘˜è¦æŠ¥å‘Š")
    print("=" * 60)

    total = len(results)
    passed = sum(1 for r in results.values() if r)
    failed = total - passed

    print(f"\næ€»æµ‹è¯•æ•°: {total}")
    print(f"é€šè¿‡: {passed} âœ…")
    print(f"å¤±è´¥: {failed} âŒ")
    print(f"é€šè¿‡ç‡: {passed / total * 100:.1f}%")

    print("\nè¯¦ç»†ç»“æœ:")
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {status}: {test_name}")

    print("\n" + "=" * 60)
    if failed == 0:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¸‚åœºåˆ†æåŠŸèƒ½ä¼˜åŒ–æˆåŠŸã€‚")
    else:
        print(f"âš ï¸ æœ‰ {failed} ä¸ªæµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤ã€‚")
    print("=" * 60)

    return failed == 0


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "ğŸš€" * 30)
    print("  å¸‚åœºåˆ†æåŠŸèƒ½ä¼˜åŒ–æµ‹è¯•")
    print("ğŸš€" * 30)
    print(f"\næµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("æµ‹è¯•é¡¹ç›®:")
    print("  1. æœç´¢æŸ¥è¯¢èŒƒå›´æ‰©å¤§")
    print("  2. çƒ­ç‚¹å…ƒç´ æå–åŠŸèƒ½")
    print("  3. å®Œæ•´å¸‚åœºåˆ†ææµç¨‹")
    print("  4. ç¼“å­˜å‘¨æœŸç¼©çŸ­")
    print("  5. ç¡¬ç¼–ç ä¿®å¤éªŒè¯")

    results = {}

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results["æœç´¢æŸ¥è¯¢ç”Ÿæˆ"] = await test_search_queries_generation()
    results["çƒ­ç‚¹å…ƒç´ æå–"] = await test_hot_elements_extraction()
    results["å®Œæ•´åˆ†ææµç¨‹"] = await test_market_analysis_with_hot_elements()
    results["ç¼“å­˜å‘¨æœŸè®¾ç½®"] = await test_cache_duration()
    results["ç¡¬ç¼–ç ä¿®å¤"] = await test_hardcoded_fix()

    # ç”ŸæˆæŠ¥å‘Š
    all_passed = generate_summary_report(results)

    return 0 if all_passed else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
