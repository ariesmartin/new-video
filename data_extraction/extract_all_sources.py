#!/usr/bin/env python3
"""
å®Œæ•´æ•°æ®æå–è„šæœ¬ - ä»æ‰€æœ‰3ä¸ªæ•°æ®æºæå–å¹¶åˆå¹¶
æ•°æ®æº:
1. google-deepresearch.html (JavaScriptæ•°æ®)
2. kimi-deepresearch.html (åº”è¯¥å’Œgoogleæ˜¯åŒä¸€ä¸ª)
3. çŸ­å‰§åˆ›ä½œä¸»é¢˜åº“ç ”ç©¶æŠ¥å‘Š.txt (JSONæ•°æ®)
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any


def extract_from_html_js(file_path: str) -> Dict:
    """ä»HTMLçš„JavaScriptä¸­æå–researchDataå¯¹è±¡"""
    print(f"ğŸ“– è¯»å–HTML JSæ•°æ®: {file_path}")

    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æå–researchDataå¯¹è±¡
    match = re.search(r"const researchData = ({.*?});", content, re.DOTALL)
    if not match:
        print("  âš ï¸ æœªæ‰¾åˆ°researchData")
        return {}

    js_data = match.group(1)

    # ç®€å•çš„JSåˆ°JSONè½¬æ¢ï¼ˆå¤„ç†å•å¼•å·ã€ç§»é™¤æ³¨é‡Šç­‰ï¼‰
    # å°†å•å¼•å·å±æ€§åè½¬æ¢ä¸ºåŒå¼•å·
    js_data = re.sub(r"([{,]\s*)(\w+)(\s*:)", r'\1"\2"\3', js_data)
    # å°†å•å¼•å·å­—ç¬¦ä¸²è½¬æ¢ä¸ºåŒå¼•å·
    js_data = js_data.replace("'", '"')
    # ç§»é™¤å°¾éƒ¨é€—å·
    js_data = re.sub(r",(\s*[}\]])", r"\1", js_data)

    try:
        data = json.loads(js_data)
        print(f"  âœ… æå–æˆåŠŸ:")
        print(f"     - é¢˜æ: {len(data.get('genres', {}))}")
        print(f"     - å…ƒç´ : {len(data.get('tropes', []))}")
        print(f"     - é’©å­: {sum(len(v) for v in data.get('hooks', {}).values())}")
        return data
    except Exception as e:
        print(f"  âŒ è§£æé”™è¯¯: {e}")
        return {}


def extract_from_txt_json(file_path: str) -> Dict:
    """ä»æ–‡æœ¬æŠ¥å‘Šä¸­æå–JSONæ•°æ®"""
    print(f"\nğŸ“– è¯»å–TXT JSONæ•°æ®: {file_path}")

    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æ‰¾åˆ°JSONéƒ¨åˆ†
    match = re.search(r"```json\n(.*?)\n```", content, re.DOTALL)
    if not match:
        print("  âš ï¸ æœªæ‰¾åˆ°JSONæ•°æ®")
        return {}

    try:
        data = json.loads(match.group(1))
        print(f"  âœ… æå–æˆåŠŸ:")
        print(f"     - é¢˜æ: {len(data.get('genres', {}))}")
        print(
            f"     - å…ƒç´ : {sum(len(v.get('tropes', [])) for v in data.get('genres', {}).values())}"
        )
        print(f"     - é’©å­: {sum(len(v) for v in data.get('hooks', {}).values())}")
        return data
    except Exception as e:
        print(f"  âŒ è§£æé”™è¯¯: {e}")
        return {}


def merge_data(html_data: Dict, txt_data: Dict) -> Dict:
    """åˆå¹¶ä¸¤ä¸ªæ•°æ®æºçš„æ•°æ®"""
    print("\nğŸ”„ åˆå¹¶æ•°æ®...")

    merged = {
        "themes": [],
        "theme_elements": [],
        "theme_examples": [],
        "hook_templates": [],
        "market_insights": {},
    }

    # 1. åˆå¹¶é¢˜ææ•°æ®ï¼ˆä»¥txtä¸ºä¸»ï¼Œhtmlè¡¥å……ï¼‰
    genre_mapping = {
        "revenge": "revenge",
        "romance": "sweet_romance",
        "mystery": "mystery",
        "rebirth": "transmigration",
        "urban": "family",
    }

    # ä»TXTæå–é¢˜æ
    for genre_key, genre_data in txt_data.get("genres", {}).items():
        slug = genre_mapping.get(genre_key, genre_key)

        theme = {
            "slug": slug,
            "name": get_genre_name(slug),
            "name_en": get_genre_name_en(slug),
            "category": get_genre_category(slug),
            "description": genre_data.get("core_formula", {}).get("setup", "")[:200],
            "summary": genre_data.get("emotional_arc", ""),
            "core_formula": {
                "setup": {
                    "description": genre_data.get("core_formula", {}).get("setup", "")
                },
                "rising": {
                    "description": genre_data.get("core_formula", {}).get("rising", "")
                },
                "climax": {
                    "description": genre_data.get("core_formula", {}).get("climax", "")
                },
                "resolution": {
                    "description": genre_data.get("core_formula", {}).get(
                        "resolution", ""
                    )
                },
            },
            "keywords": {
                "writing": genre_data.get("writing_keywords", []),
                "visual": genre_data.get("visual_keywords", []),
            },
            "audience_analysis": genre_data.get("target_audience", {}),
            "market_score": calculate_market_score(slug),
            "success_rate": 85.0,
        }
        merged["themes"].append(theme)

        # æå–å…ƒç´ 
        for trope in genre_data.get("tropes", []):
            element = {
                "genre_slug": slug,
                "element_type": "trope",
                "name": trope.get("name", ""),
                "description": trope.get("description", ""),
                "effectiveness_score": trope.get("effectiveness_score", 0),
                "weight": 1.0,
                "usage_guidance": {
                    "best_timing": trope.get("usage_timing", ""),
                    "preparation": "",
                    "execution_tips": "",
                    "variations": [],
                },
                "emotional_impact": {
                    "satisfaction": trope.get("effectiveness_score", 0),
                    "surprise": 85,
                    "replay_value": 80,
                },
                "classic_examples": [
                    {
                        "drama": ex.split("ã€‹")[0].replace("ã€Š", "").strip()
                        if "ã€‹" in ex
                        else ex,
                        "scene": ex,
                    }
                    for ex in trope.get("examples", [])
                ],
            }
            merged["theme_elements"].append(element)

        # æå–æ¡ˆä¾‹
        for example in genre_data.get("viral_examples", []):
            example_data = {
                "genre_slug": slug,
                "example_type": "drama",
                "title": example.get("title", ""),
                "description": example.get("why_it_works", ""),
                "achievements": {
                    "description": example.get("why_it_works", ""),
                    "awards": [],
                },
                "key_success_factors": [example.get("why_it_works", "")],
                "is_verified": True,
                "verification_source": "Deep Research Report",
            }
            merged["theme_examples"].append(example_data)

    # 2. åˆå¹¶å…¨å±€tropesï¼ˆä»txtï¼‰
    for trope_key, trope_data in txt_data.get("tropes", {}).items():
        hook = {
            "hook_type": "trope",
            "name": trope_data.get("name", ""),
            "description": trope_data.get("description", ""),
            "template": "",
            "variables": {},
            "effectiveness_score": trope_data.get("success_rate", 0),
            "psychology_mechanism": "",
            "usage_constraints": {
                "best_timing": trope_data.get("usage_guidelines", {}).get(
                    "best_timing", ""
                ),
                "preparation": trope_data.get("usage_guidelines", {}).get(
                    "preparation", ""
                ),
                "execution": trope_data.get("usage_guidelines", {}).get(
                    "execution", ""
                ),
            },
            "applicable_genres": [],
            "examples": trope_data.get("classic_examples", []),
            "emotional_impact": trope_data.get("emotional_impact", {}),
            "risk_factors": trope_data.get("risk_factors", []),
        }
        merged["hook_templates"].append(hook)

    # 3. åˆå¹¶hooksï¼ˆä»txtï¼‰
    for hook_type, hooks in txt_data.get("hooks", {}).items():
        for hook_data in hooks:
            hook = {
                "hook_type": hook_type.replace("_hooks", ""),
                "name": hook_data.get("name", ""),
                "template": hook_data.get("template", ""),
                "variables": hook_data.get("variables", {}),
                "effectiveness_score": hook_data.get("effectiveness_score", 0),
                "psychology_mechanism": hook_data.get("usage_tips", ""),
                "usage_constraints": {"duration": "å‰30ç§’"},
                "applicable_genres": hook_data.get("applicable_genres", []),
                "examples": hook_data.get("examples", []),
            }
            merged["hook_templates"].append(hook)

    # 4. ä»HTMLè¡¥å……é¢å¤–çš„hookså’Œtropesï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    html_hooks = html_data.get("hooks", {})
    for hook_type, hooks in html_hooks.items():
        for hook_data in hooks:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing = [
                h
                for h in merged["hook_templates"]
                if h.get("name") == hook_data.get("title")
            ]
            if not existing:
                hook = {
                    "hook_type": hook_type,
                    "name": hook_data.get("title", ""),
                    "template": hook_data.get("template", ""),
                    "variables": {},
                    "effectiveness_score": hook_data.get("score", 0),
                    "psychology_mechanism": "",
                    "usage_constraints": {},
                    "applicable_genres": [],
                    "examples": [],
                }
                merged["hook_templates"].append(hook)

    # ä»HTMLè¡¥å……tropes
    html_tropes = html_data.get("tropes", [])
    for trope in html_tropes:
        existing = [
            e for e in merged["theme_elements"] if e.get("name") == trope.get("name")
        ]
        if not existing:
            element = {
                "genre_slug": "general",
                "element_type": trope.get("category", "trope"),
                "name": trope.get("name", ""),
                "description": trope.get("desc", ""),
                "effectiveness_score": trope.get("score", 0),
                "weight": 1.0,
                "usage_guidance": {
                    "best_timing": trope.get("timing", ""),
                    "preparation": "",
                    "execution_tips": "",
                    "variations": [],
                },
            }
            merged["theme_elements"].append(element)

    # 5. å¸‚åœºæ´å¯Ÿ
    metadata = txt_data.get("research_metadata", {})
    merged["market_insights"] = {
        "period": "2024-2025",
        "key_findings": metadata.get("data_sources", []),
        "total_tropes": metadata.get("total_tropes", 0),
        "total_hooks": metadata.get("total_hooks", 0),
        "market_size_2024": "504.4äº¿",
        "market_size_2025": "634äº¿",
        "user_count_2024": "6.62äº¿",
        "user_count_2025": "6.96äº¿",
    }

    return merged


def get_genre_name(slug: str) -> str:
    names = {
        "revenge": "å¤ä»‡é€†è¢­",
        "sweet_romance": "ç”œå® æ‹çˆ±",
        "mystery": "æ‚¬ç–‘æ¨ç†",
        "transmigration": "ç©¿è¶Šé‡ç”Ÿ",
        "family": "å®¶åº­ä¼¦ç†",
    }
    return names.get(slug, slug)


def get_genre_name_en(slug: str) -> str:
    names = {
        "revenge": "Revenge & Comeback",
        "sweet_romance": "Sweet Romance",
        "mystery": "Mystery & Suspense",
        "transmigration": "Transmigration & Rebirth",
        "family": "Family & Urban Reality",
    }
    return names.get(slug, slug)


def get_genre_category(slug: str) -> str:
    categories = {
        "revenge": "drama",
        "sweet_romance": "romance",
        "mystery": "thriller",
        "transmigration": "fantasy",
        "family": "drama",
    }
    return categories.get(slug, "drama")


def calculate_market_score(slug: str) -> float:
    scores = {
        "revenge": 95.5,
        "sweet_romance": 88.0,
        "mystery": 82.0,
        "transmigration": 90.0,
        "family": 75.0,
    }
    return scores.get(slug, 80.0)


def save_json(data: Dict, output_path: str):
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²ä¿å­˜: {output_path}")


def main():
    print("=" * 70)
    print("ğŸš€ å®Œæ•´æ•°æ®æå– - ä»æ‰€æœ‰3ä¸ªæ•°æ®æº")
    print("=" * 70)

    # æ–‡ä»¶è·¯å¾„
    html_file = "/Users/ariesmartin/Documents/new-video/google-deepresearch.html"
    txt_file = "/Users/ariesmartin/Documents/new-video/çŸ­å‰§åˆ›ä½œä¸»é¢˜åº“ç ”ç©¶æŠ¥å‘Š.txt"

    # 1. ä»HTMLæå–
    html_data = extract_from_html_js(html_file)

    # 2. ä»TXTæå–
    txt_data = extract_from_txt_json(txt_file)

    if not txt_data:
        print("âŒ æ— æ³•ä»ä¸»æ•°æ®æºæå–æ•°æ®")
        return

    # 3. åˆå¹¶æ•°æ®
    merged_data = merge_data(html_data, txt_data)

    # 4. ç»Ÿè®¡
    print("\nğŸ“Š æœ€ç»ˆæ•°æ®ç»Ÿè®¡:")
    print(f"   - é¢˜ææ•°é‡: {len(merged_data['themes'])}")
    print(f"   - çˆ†æ¬¾å…ƒç´ : {len(merged_data['theme_elements'])}")
    print(f"   - æ ‡æ†æ¡ˆä¾‹: {len(merged_data['theme_examples'])}")
    print(f"   - é’©å­æ¨¡æ¿: {len(merged_data['hook_templates'])}")

    # 5. ä¿å­˜å®Œæ•´æ•°æ®
    save_json(
        merged_data,
        "/Users/ariesmartin/Documents/new-video/data_extraction/merged_all_sources.json",
    )

    # 6. ä¿å­˜åˆ†è¡¨æ•°æ®
    save_json(
        {"themes": merged_data["themes"]},
        "/Users/ariesmartin/Documents/new-video/data_extraction/seed_themes_final.json",
    )

    save_json(
        {"theme_elements": merged_data["theme_elements"]},
        "/Users/ariesmartin/Documents/new-video/data_extraction/seed_elements_final.json",
    )

    save_json(
        {"theme_examples": merged_data["theme_examples"]},
        "/Users/ariesmartin/Documents/new-video/data_extraction/seed_examples_final.json",
    )

    save_json(
        {"hook_templates": merged_data["hook_templates"]},
        "/Users/ariesmartin/Documents/new-video/data_extraction/seed_hooks_final.json",
    )

    print("\n" + "=" * 70)
    print("âœ… æ•°æ®æå–å®Œæˆï¼")
    print("=" * 70)
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print("  1. merged_all_sources.json - å®Œæ•´åˆå¹¶æ•°æ®")
    print("  2. seed_themes_final.json - é¢˜ææ•°æ®")
    print("  3. seed_elements_final.json - å…ƒç´ æ•°æ®")
    print("  4. seed_examples_final.json - æ¡ˆä¾‹æ•°æ®")
    print("  5. seed_hooks_final.json - é’©å­æ¨¡æ¿")


if __name__ == "__main__":
    main()
