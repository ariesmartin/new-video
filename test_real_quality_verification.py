#!/usr/bin/env python3
"""
å¸‚åœºåˆ†æåŠŸèƒ½ - çœŸå®å…¨æµç¨‹è´¨é‡éªŒè¯æµ‹è¯•

çœŸå®æ‰§è¡Œä»¥ä¸‹æµç¨‹ï¼š
1. è°ƒç”¨çœŸå®æœç´¢APIè·å–æ•°æ®
2. éªŒè¯æœç´¢å†…å®¹çš„è´¨é‡ï¼ˆæ˜¯å¦åŒ…å«çŸ­å‰§ç›¸å…³ä¿¡æ¯ï¼‰
3. ä½¿ç”¨LLMåˆ†æå¹¶æå–çƒ­ç‚¹å…ƒç´ 
4. éªŒè¯æå–ç»“æœçš„è´¨é‡
5. æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
6. éªŒè¯æ˜¯å¦å¯ä»¥è¢«Story Planneræ­£ç¡®ä½¿ç”¨

ç¯å¢ƒè¦æ±‚ï¼š
- éœ€è¦é…ç½®å¥½çš„MetaSo API Key
- éœ€è¦LLMæœåŠ¡å¯ç”¨

è¿è¡Œï¼š
    cd /Users/ariesmartin/Documents/new-video
    source backend/.venv/bin/activate
    python test_real_quality_verification.py
"""

import asyncio
import sys
import json
import re
from datetime import datetime
from typing import Dict, List, Any

sys.path.insert(0, "/Users/ariesmartin/Documents/new-video")


class QualityMetrics:
    """è´¨é‡è¯„ä¼°æŒ‡æ ‡"""

    def __init__(self):
        self.checks = []

    def check(self, name: str, condition: bool, details: str = ""):
        """è®°å½•æ£€æŸ¥ç»“æœ"""
        status = "âœ…" if condition else "âŒ"
        self.checks.append(
            {"name": name, "passed": condition, "details": details, "status": status}
        )
        print(f"{status} {name}")
        if details:
            print(f"   {details}")
        return condition

    def summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ‘˜è¦"""
        passed = sum(1 for c in self.checks if c["passed"])
        total = len(self.checks)
        return {
            "passed": passed,
            "total": total,
            "rate": passed / total if total > 0 else 0,
            "checks": self.checks,
        }


async def test_real_search_quality():
    """æµ‹è¯•1: çœŸå®æœç´¢APIè°ƒç”¨å’Œå†…å®¹è´¨é‡"""
    print("\n" + "=" * 70)
    print("ã€æµ‹è¯•1ã€‘çœŸå®æœç´¢APIè°ƒç”¨å’Œå†…å®¹è´¨é‡éªŒè¯")
    print("=" * 70)

    metrics = QualityMetrics()

    try:
        from backend.tools.metaso_search import metaso_search

        # å®šä¹‰æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "2026å¹´çŸ­å‰§çƒ­é—¨å…ƒç´ ",
            "2026å¹´çŸ­å‰§æ–°å…´é¢˜æ",
        ]

        search_results = []

        for query in test_queries:
            print(f"\næ‰§è¡Œæœç´¢: {query}")
            print("-" * 50)

            try:
                result = await metaso_search.ainvoke(query)
                result_length = len(result)

                print(f"ç»“æœé•¿åº¦: {result_length} å­—ç¬¦")
                print(f"ç»“æœé¢„è§ˆ:\n{result[:500]}...")

                # è´¨é‡æ£€æŸ¥1: ç»“æœé•¿åº¦
                has_content = metrics.check(
                    "ç»“æœéç©º", result_length > 100, f"é•¿åº¦: {result_length} å­—ç¬¦"
                )

                if not has_content:
                    continue

                # è´¨é‡æ£€æŸ¥2: æ˜¯å¦åŒ…å«çŸ­å‰§ç›¸å…³ä¿¡æ¯
                short_drama_keywords = [
                    "çŸ­å‰§",
                    "å‰§å",
                    "çˆ†æ¬¾",
                    "çƒ­åº¦",
                    "æ’­æ”¾é‡",
                    "é¢˜æ",
                ]
                found_keywords = [kw for kw in short_drama_keywords if kw in result]

                metrics.check(
                    "åŒ…å«çŸ­å‰§ç›¸å…³å…³é”®è¯",
                    len(found_keywords) >= 2,
                    f"æ‰¾åˆ°å…³é”®è¯: {', '.join(found_keywords[:5])}",
                )

                # è´¨é‡æ£€æŸ¥3: æ˜¯å¦åŒ…å«å…·ä½“å‰§åï¼ˆä¹¦åå·ï¼‰
                drama_names = re.findall(r"ã€Š([^ã€‹]+)ã€‹", result)
                metrics.check(
                    "åŒ…å«å…·ä½“å‰§å",
                    len(drama_names) > 0,
                    f"æ‰¾åˆ° {len(drama_names)} ä¸ªå‰§å: {', '.join(drama_names[:3])}",
                )

                # è´¨é‡æ£€æŸ¥4: æ˜¯å¦åŒ…å«é¢˜æ/å…ƒç´ ä¿¡æ¯
                genre_keywords = [
                    "ç©¿è¶Š",
                    "é‡ç”Ÿ",
                    "ç”œå® ",
                    "å¤ä»‡",
                    "æ‚¬ç–‘",
                    "éƒ½å¸‚",
                    "å¤è£…",
                ]
                found_genres = [kw for kw in genre_keywords if kw in result]

                metrics.check(
                    "åŒ…å«é¢˜æ/å…ƒç´ ä¿¡æ¯",
                    len(found_genres) > 0,
                    f"æ‰¾åˆ°é¢˜æ: {', '.join(found_genres[:5])}",
                )

                search_results.append(
                    {
                        "query": query,
                        "result": result,
                        "length": result_length,
                        "drama_names": drama_names,
                        "genres": found_genres,
                    }
                )

            except Exception as e:
                print(f"âŒ æœç´¢å¤±è´¥: {e}")
                metrics.check("æœç´¢æˆåŠŸ", False, str(e))

        summary = metrics.summary()
        print(f"\næœç´¢è´¨é‡è¯„ä¼°: {summary['passed']}/{summary['total']} é€šè¿‡")

        return search_results, summary

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return [], {"passed": 0, "total": 1, "rate": 0}


def simple_extract_hot_elements(search_results: List[Dict]) -> Dict[str, Any]:
    """ç®€åŒ–ç‰ˆçƒ­ç‚¹å…ƒç´ æå–ï¼ˆä¸ä¾èµ–LLMï¼ŒåŸºäºè§„åˆ™ï¼‰"""
    print("\n" + "=" * 70)
    print("ã€æµ‹è¯•2ã€‘çƒ­ç‚¹å…ƒç´ æå–ï¼ˆåŸºäºè§„åˆ™ï¼‰")
    print("=" * 70)

    metrics = QualityMetrics()

    all_text = "\n".join([r["result"] for r in search_results])

    # æå–å‰§å
    drama_names = list(set(re.findall(r"ã€Š([^ã€‹]+)ã€‹", all_text)))

    # æå–çƒ­é—¨å…ƒç´ ï¼šæ‰©å¤§å€™é€‰æ± ä»10ä¸ªåˆ°20ä¸ª
    trope_keywords = {
        "èº«ä»½é”™ä½": ["èº«ä»½", "é”™ä½", "äº’æ¢", "çµé­‚äº’æ¢"],
        "åå·®èŒ": ["åå·®", "èŒ", "åå·®èŒ"],
        "åŒé‡äººæ ¼": ["åŒé‡äººæ ¼", "äººæ ¼åˆ†è£‚"],
        "é€†è¢­æˆé•¿": ["é€†è¢­", "æˆé•¿", "æ‰“è„¸", "çˆ½æ–‡", "å‡çº§"],
        "éšè—å¤§ä½¬": ["éšè—", "å¤§ä½¬", "é©¬ç”²", "æ‰é©¬", "çœŸå¤§ä½¬"],
        "åæ´¾æ´—ç™½": ["åæ´¾", "æ´—ç™½", "æ•‘èµ", "é»‘åŒ–"],
        "ç©¿ä¹¦": ["ç©¿ä¹¦", "ç©¿è¿›", "ç©¿æˆ"],
        "ç³»ç»Ÿæµ": ["ç³»ç»Ÿ", "é‡‘æ‰‹æŒ‡", "ä»»åŠ¡", "ç»‘å®š"],
        "æ›¿èº«æ–‡å­¦": ["æ›¿èº«", "ç™½æœˆå…‰", "æ›¿èº«æ–‡å­¦", "æ›¿å«"],
        "ä¹…åˆ«é‡é€¢": ["ä¹…åˆ«", "é‡é€¢", "åˆæ‹", "é’æ¢…ç«¹é©¬"],
        "å…ˆå©šåçˆ±": ["å…ˆå©šåçˆ±", "å¥‘çº¦å©šå§»", "é—ªå©š"],
        "è™æ‹æƒ…æ·±": ["è™æ‹", "è™æ–‡", "è¿½å¦»", "ç«è‘¬åœº"],
        "ç”œå® ": ["ç”œå® ", "é«˜ç”œ", "æ’’ç³–"],
        "éœ¸æ€»": ["éœ¸æ€»", "éœ¸é“æ€»è£", "æ€»è£"],
        "é‡ç”Ÿ": ["é‡ç”Ÿ", "é‡ç”Ÿä¹‹", "å†æ¥ä¸€æ¬¡"],
        "ç©¿è¶Š": ["ç©¿è¶Š", "ç©¿è¶Šåˆ°", "å¤ä»£", "å¼‚ä¸–"],
        "ä¿®ä»™": ["ä¿®ä»™", "ä»™ä¾ ", "ä¿®çœŸ", "ç„å¹»"],
        "èŒåœº": ["èŒåœº", "å•†æˆ˜", "åˆ›ä¸š", "å‡èŒ"],
        "æ‚¬ç–‘": ["æ‚¬ç–‘", "æ¨ç†", "æ¢æ¡ˆ", "åˆ‘ä¾¦"],
        "å¤ä»‡": ["å¤ä»‡", "æŠ¥ä»‡", "é›ªæ¨"],
    }

    found_tropes = []
    for trope, keywords in trope_keywords.items():
        if any(kw in all_text for kw in keywords):
            found_tropes.append(trope)

    # æå–é¢˜æ
    genre_keywords = [
        "ç©¿è¶Š",
        "é‡ç”Ÿ",
        "ç”œå® ",
        "å¤ä»‡",
        "æ‚¬ç–‘",
        "éƒ½å¸‚",
        "å¤è£…",
        "ä»™ä¾ ",
        "ç°ä»£",
        "æ°‘å›½",
    ]
    found_genres = [kw for kw in genre_keywords if kw in all_text]

    # æå–æ–°å…´ç»„åˆ
    combinations = []
    if "æ— é™æµ" in all_text and ("æ‹çˆ±" in all_text or "ç”œå® " in all_text):
        combinations.append("æ— é™æµ+æ‹çˆ±")
    if "èµ›åš" in all_text and ("åŒ»ç–—" in all_text or "åŒ»é™¢" in all_text):
        combinations.append("èµ›åšæœ‹å…‹+åŒ»ç–—")
    if "æœ«ä¸–" in all_text and ("ç¾é£Ÿ" in all_text or "æ–™ç†" in all_text):
        combinations.append("æœ«ä¸–+ç¾é£Ÿ")

    hot_elements = {
        "hot_tropes": found_tropes[:10],
        "hot_settings": found_genres[:5],
        "hot_character_types": [],
        "emerging_combinations": combinations,
        "overused_tropes": ["éœ¸é“æ€»è£çˆ±ä¸Šæˆ‘", "é‡ç”Ÿå¤ä»‡"],
        "specific_works": drama_names[:10],
        "_extraction_method": "rule_based",
        "_source_text_length": len(all_text),
    }

    # è´¨é‡æ£€æŸ¥
    print(f"\næå–ç»“æœ:")
    print(f"çƒ­é—¨å…ƒç´ : {len(hot_elements['hot_tropes'])} ä¸ª")
    if hot_elements["hot_tropes"]:
        print(f"  ç¤ºä¾‹: {', '.join(hot_elements['hot_tropes'][:5])}")

    print(f"çƒ­é—¨èƒŒæ™¯: {len(hot_elements['hot_settings'])} ä¸ª")
    if hot_elements["hot_settings"]:
        print(f"  ç¤ºä¾‹: {', '.join(hot_elements['hot_settings'][:5])}")

    print(f"æ–°å…´ç»„åˆ: {len(hot_elements['emerging_combinations'])} ä¸ª")
    if hot_elements["emerging_combinations"]:
        print(f"  ç¤ºä¾‹: {', '.join(hot_elements['emerging_combinations'])}")

    print(f"å‚è€ƒå‰§å: {len(hot_elements['specific_works'])} ä¸ª")
    if hot_elements["specific_works"]:
        print(
            f"  ç¤ºä¾‹: {', '.join(['ã€Š' + w + 'ã€‹' for w in hot_elements['specific_works'][:3]])}"
        )

    # è´¨é‡è¯„ä¼°
    metrics.check(
        "æå–åˆ°çƒ­é—¨å…ƒç´ ",
        len(hot_elements["hot_tropes"]) > 0,
        f"{len(hot_elements['hot_tropes'])} ä¸ªå…ƒç´ ",
    )

    metrics.check(
        "æå–åˆ°é¢˜æä¿¡æ¯",
        len(hot_elements["hot_settings"]) > 0,
        f"{len(hot_elements['hot_settings'])} ä¸ªé¢˜æ",
    )

    metrics.check(
        "æå–åˆ°å…·ä½“å‰§å",
        len(hot_elements["specific_works"]) > 0,
        f"{len(hot_elements['specific_works'])} ä¸ªå‰§å",
    )

    summary = metrics.summary()
    print(f"\næå–è´¨é‡è¯„ä¼°: {summary['passed']}/{summary['total']} é€šè¿‡")

    return hot_elements, summary


def test_data_usability(hot_elements: Dict) -> Dict[str, Any]:
    """æµ‹è¯•3: éªŒè¯æ•°æ®å¯ç”¨æ€§ï¼ˆä¾›Story Plannerä½¿ç”¨ï¼‰"""
    print("\n" + "=" * 70)
    print("ã€æµ‹è¯•3ã€‘æ•°æ®å¯ç”¨æ€§éªŒè¯ï¼ˆä¾›Story Plannerä½¿ç”¨ï¼‰")
    print("=" * 70)

    metrics = QualityMetrics()

    # æ£€æŸ¥å¿…è¦å­—æ®µ
    required_fields = [
        "hot_tropes",
        "hot_settings",
        "hot_character_types",
        "emerging_combinations",
        "overused_tropes",
        "specific_works",
    ]

    for field in required_fields:
        has_field = field in hot_elements
        is_list = isinstance(hot_elements.get(field), list) if has_field else False
        metrics.check(
            f"å­—æ®µ '{field}' å­˜åœ¨ä¸”ä¸ºåˆ—è¡¨",
            has_field and is_list,
            f"ç±»å‹: {type(hot_elements.get(field)).__name__}",
        )

    # æ£€æŸ¥æ•°æ®æ ¼å¼
    print("\næ•°æ®ç»“æ„æ£€æŸ¥:")
    print(json.dumps(hot_elements, indent=2, ensure_ascii=False))

    # éªŒè¯æ˜¯å¦å¯ä»¥ç”ŸæˆPrompt
    print("\nç”ŸæˆPromptç¤ºä¾‹ï¼ˆä¾›Story Plannerä½¿ç”¨ï¼‰:\n")

    prompt_section = f"""
## ğŸ“Š å½“å‰å¸‚åœºçƒ­ç‚¹æ•°æ®ï¼ˆå¿…é¡»ä½¿ç”¨ï¼‰

### ğŸ”¥ çƒ­é—¨å…ƒç´ ï¼ˆé€‰æ‹©è‡³å°‘2ä¸ªï¼‰
{chr(10).join([f"- {trope}" for trope in hot_elements.get("hot_tropes", [])[:6]])}

### ğŸ  çƒ­é—¨èƒŒæ™¯ï¼ˆé€‰æ‹©1ä¸ªï¼‰
{chr(10).join([f"- {setting}" for setting in hot_elements.get("hot_settings", [])[:4]])}

### ğŸ†• æ–°å…´ç»„åˆï¼ˆå°è¯•1ä¸ªï¼‰
{chr(10).join([f"- {combo}" for combo in hot_elements.get("emerging_combinations", [])[:3]])}

### ğŸš« é¿å…ä½¿ç”¨ï¼ˆå·²è¿‡åº¦ï¼‰
{chr(10).join([f"- âŒ {trope}" for trope in hot_elements.get("overused_tropes", [])[:3]])}

### ğŸ¬ å‚è€ƒçˆ†æ¬¾å‰§ï¼ˆäº†è§£å¸‚åœºï¼‰
{chr(10).join([f"- ã€Š{work}ã€‹" for work in hot_elements.get("specific_works", [])[:3]])}

### âš ï¸ å¼ºåˆ¶è§„åˆ™
1. å¿…é¡»ä»ã€çƒ­é—¨å…ƒç´ ã€‘ä¸­é€‰æ‹©è‡³å°‘2ä¸ªèå…¥æ–¹æ¡ˆ
2. å¿…é¡»å°è¯•ã€æ–°å…´ç»„åˆã€‘ä¸­çš„è‡³å°‘1ä¸ª
3. ä¸¥ç¦ä½¿ç”¨ã€é¿å…ä½¿ç”¨ã€‘ä¸­çš„å…ƒç´ ä½œä¸ºä¸»è¦å–ç‚¹
"""

    print(prompt_section)

    # æ£€æŸ¥Promptè´¨é‡
    has_tropes = len(hot_elements.get("hot_tropes", [])) >= 2
    has_works = len(hot_elements.get("specific_works", [])) > 0

    metrics.check(
        "PromptåŒ…å«è¶³å¤Ÿçš„çƒ­é—¨å…ƒç´ (>=2)",
        has_tropes,
        f"{len(hot_elements.get('hot_tropes', []))} ä¸ª",
    )

    metrics.check(
        "PromptåŒ…å«å‚è€ƒå‰§å",
        has_works,
        f"{len(hot_elements.get('specific_works', []))} ä¸ª",
    )

    summary = metrics.summary()
    print(f"\nå¯ç”¨æ€§è¯„ä¼°: {summary['passed']}/{summary['total']} é€šè¿‡")

    return summary


def test_diversity(hot_elements_list: List[Dict]):
    """æµ‹è¯•4: éªŒè¯æ•°æ®å¤šæ ·æ€§ï¼ˆå¤šæ¬¡æå–ç»“æœæ˜¯å¦ä¸åŒï¼‰"""
    print("\n" + "=" * 70)
    print("ã€æµ‹è¯•4ã€‘æ•°æ®å¤šæ ·æ€§éªŒè¯")
    print("=" * 70)

    if len(hot_elements_list) < 2:
        print("âš ï¸ åªæœ‰ä¸€æ¬¡æå–ç»“æœï¼Œæ— æ³•éªŒè¯å¤šæ ·æ€§")
        return {"passed": 0, "total": 1, "rate": 0}

    metrics = QualityMetrics()

    # æ¯”è¾ƒä¸¤æ¬¡æå–ç»“æœ
    first = hot_elements_list[0]
    second = (
        hot_elements_list[1] if len(hot_elements_list) > 1 else hot_elements_list[0]
    )

    first_tropes = set(first.get("hot_tropes", []))
    second_tropes = set(second.get("hot_tropes", []))

    overlap = len(first_tropes & second_tropes)
    total_unique = len(first_tropes | second_tropes)

    print(f"\nç¬¬ä¸€æ¬¡æå–: {len(first_tropes)} ä¸ªå…ƒç´ ")
    print(f"  {', '.join(list(first_tropes)[:5])}")

    print(f"\nç¬¬äºŒæ¬¡æå–: {len(second_tropes)} ä¸ªå…ƒç´ ")
    print(f"  {', '.join(list(second_tropes)[:5])}")

    print(f"\né‡å å…ƒç´ : {overlap} ä¸ª")
    print(f"ç‹¬ç‰¹å…ƒç´ : {total_unique} ä¸ª")
    print(f"é‡å ç‡: {overlap / len(first_tropes) * 100:.1f}%" if first_tropes else "0%")

    # æ£€æŸ¥å¤šæ ·æ€§
    is_diverse = overlap < len(first_tropes) * 0.8  # é‡å ç‡<80%è®¤ä¸ºå¤šæ ·

    metrics.check(
        "æå–ç»“æœå…·æœ‰å¤šæ ·æ€§ï¼ˆé‡å <80%ï¼‰",
        is_diverse,
        f"é‡å ç‡: {overlap / len(first_tropes) * 100:.1f}%" if first_tropes else "N/A",
    )

    summary = metrics.summary()
    print(f"\nå¤šæ ·æ€§è¯„ä¼°: {summary['passed']}/{summary['total']} é€šè¿‡")

    return summary


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ§ª" * 35)
    print("  å¸‚åœºåˆ†æåŠŸèƒ½ - çœŸå®è´¨é‡éªŒè¯æµ‹è¯•")
    print("ğŸ§ª" * 35)
    print(f"\næµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\næµ‹è¯•å†…å®¹:")
    print("  1. çœŸå®æœç´¢APIè°ƒç”¨å’Œå†…å®¹è´¨é‡")
    print("  2. çƒ­ç‚¹å…ƒç´ æå–è´¨é‡")
    print("  3. æ•°æ®å¯ç”¨æ€§ï¼ˆä¾›Story Plannerä½¿ç”¨ï¼‰")
    print("  4. æ•°æ®å¤šæ ·æ€§")

    all_results = {}

    # æµ‹è¯•1: çœŸå®æœç´¢
    print("\n\n" + "ğŸš€" * 35)
    print("å¼€å§‹æ‰§è¡ŒçœŸå®æœç´¢...")
    print("ğŸš€" * 35)
    search_results, search_quality = await test_real_search_quality()
    all_results["æœç´¢è´¨é‡"] = search_quality

    if not search_results:
        print("\nâŒ æœç´¢å¤±è´¥ï¼Œæ— æ³•ç»§ç»­åç»­æµ‹è¯•")
        return 1

    # æµ‹è¯•2: çƒ­ç‚¹å…ƒç´ æå–
    print("\n\n" + "ğŸ”" * 35)
    print("å¼€å§‹æå–çƒ­ç‚¹å…ƒç´ ...")
    print("ğŸ”" * 35)
    hot_elements, extract_quality = simple_extract_hot_elements(search_results)
    all_results["æå–è´¨é‡"] = extract_quality

    # æµ‹è¯•3: æ•°æ®å¯ç”¨æ€§
    print("\n\n" + "âœ…" * 35)
    print("éªŒè¯æ•°æ®å¯ç”¨æ€§...")
    print("âœ…" * 35)
    usability_quality = test_data_usability(hot_elements)
    all_results["å¯ç”¨æ€§"] = usability_quality

    # æµ‹è¯•4: å¤šæ ·æ€§ï¼ˆå¯é€‰ï¼Œéœ€è¦å¤šæ¬¡æœç´¢ï¼‰
    print("\n\n" + "ğŸ²" * 35)
    print("éªŒè¯å¤šæ ·æ€§...")
    print("ğŸ²" * 35)
    diversity_quality = test_diversity([hot_elements])
    all_results["å¤šæ ·æ€§"] = diversity_quality

    # æœ€ç»ˆæŠ¥å‘Š
    print("\n\n" + "=" * 70)
    print("ğŸ“Š æœ€ç»ˆè´¨é‡è¯„ä¼°æŠ¥å‘Š")
    print("=" * 70)

    total_passed = 0
    total_checks = 0

    for category, result in all_results.items():
        passed = result.get("passed", 0)
        total = result.get("total", 0)
        rate = result.get("rate", 0)

        total_passed += passed
        total_checks += total

        print(f"\nã€{category}ã€‘")
        print(f"  é€šè¿‡: {passed}/{total} ({rate * 100:.0f}%)")

        # æ‰“å°å¤±è´¥çš„æ£€æŸ¥
        for check in result.get("checks", []):
            if not check["passed"]:
                print(f"  âŒ {check['name']}: {check['details']}")

    overall_rate = total_passed / total_checks if total_checks > 0 else 0

    print("\n" + "=" * 70)
    print(f"æ€»ä½“è¯„ä¼°: {total_passed}/{total_checks} é€šè¿‡ ({overall_rate * 100:.1f}%)")
    print("=" * 70)

    if overall_rate >= 0.8:
        print("\nğŸ‰ è´¨é‡éªŒè¯é€šè¿‡ï¼")
        print("\nç»“è®º:")
        print("  âœ… æœç´¢APIè¿”å›çš„å†…å®¹è´¨é‡è‰¯å¥½")
        print("  âœ… æå–çš„çƒ­ç‚¹å…ƒç´ å‡†ç¡®ä¸”ç›¸å…³")
        print("  âœ… æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå¯ä¾›Story Plannerä½¿ç”¨")
        print("  âœ… ç³»ç»Ÿå¯ä»¥åŸºäºè¿™äº›æ•°æ®ç”Ÿæˆå¤šæ ·åŒ–çš„æ–¹æ¡ˆ")
    elif overall_rate >= 0.5:
        print("\nâš ï¸  è´¨é‡éªŒè¯éƒ¨åˆ†é€šè¿‡")
        print("\nå»ºè®®:")
        print("  â€¢ æ£€æŸ¥æœç´¢APIè¿”å›çš„å†…å®¹æ˜¯å¦ç›¸å…³")
        print("  â€¢ ä¼˜åŒ–æå–è§„åˆ™æˆ–Prompt")
        print("  â€¢ å¢åŠ æ›´å¤šå…³é”®è¯åŒ¹é…")
    else:
        print("\nâŒ è´¨é‡éªŒè¯æœªé€šè¿‡")
        print("\néœ€è¦æ£€æŸ¥:")
        print("  â€¢ æœç´¢APIæ˜¯å¦æ­£å¸¸å·¥ä½œ")
        print("  â€¢ æå–é€»è¾‘æ˜¯å¦æ­£ç¡®")
        print("  â€¢ å…³é”®è¯åº“æ˜¯å¦éœ€è¦æ›´æ–°")

    print("=" * 70)

    return 0 if overall_rate >= 0.5 else 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
